{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "try103.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJuUozc7ErKd"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, Input\n",
        "import numpy as np\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split \n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoeSE-Aanj0o"
      },
      "source": [
        "def prepare_datasets(test_size, validation_size, X, y):\n",
        "    \"\"\"Loads data and splits it into train, validation and test sets.\n",
        "    :param test_size (float): Value in [0, 1] indicating percentage of data set to allocate to test split\n",
        "    :param validation_size (float): Value in [0, 1] indicating percentage of train set to allocate to validation split\n",
        "    :return X_train (ndarray): Input training set\n",
        "    :return X_validation (ndarray): Input validation set\n",
        "    :return X_test (ndarray): Input test set\n",
        "    :return y_train (ndarray): Target training set\n",
        "    :return y_validation (ndarray): Target validation set\n",
        "    :return y_test (ndarray): Target test set\n",
        "    \"\"\"\n",
        "\n",
        "    # load data\n",
        "    #X, y = load_data()\n",
        "\n",
        "    # create train, validation and test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
        "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
        "\n",
        "    return X_train, X_validation, X_test, y_train, y_validation, y_test"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6r8sExcWLdO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5f6dfef-348c-4834-c846-e449582ba107"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENHIJLUzpyEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc16fc7e-651c-4df8-87f5-80aad2deb9b2"
      },
      "source": [
        "data = []\n",
        "labels = []\n",
        "DATADIR = \"/content/drive/MyDrive/data4\"\n",
        "\n",
        "CATEGORIES = [\"cough_i\", \"not cough\"]\n",
        "training_data = []\n",
        "for category in CATEGORIES:  # do cough and notcough\n",
        "\n",
        "    path = os.path.join(DATADIR,category)  # create path to cough and notcough\n",
        "    print(path)\n",
        "    class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=cough 1=notcough\n",
        "\n",
        "    for img in tqdm(os.listdir(path)):  # iterate over each image per cough and notcough\n",
        "        try:\n",
        "            img_array = cv2.imread(os.path.join(path,img))  # convert to array\n",
        "            new_array = cv2.resize(img_array, (224, 224))  # resize to normalize data size\n",
        "            #image = preprocess_input(new_array)\n",
        "            training_data.append([new_array, class_num])  # add this to our training_data\n",
        "        except Exception as e:  # in the interest in keeping the output clean...\n",
        "            pass\n",
        "        \n",
        "random.shuffle(training_data)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for features,label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "X = np.array(X).reshape(-1, 224, 224, 3)\n",
        "data = np.array(X, dtype=\"float32\")\n",
        "labels = np.array(y)\n",
        "print(labels)\n",
        "# perform one-hot encoding on the labels\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels = to_categorical(labels)\n",
        "print(labels)\n",
        "#(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "\t#test_size=0.20, stratify=labels, random_state=42)\n",
        "# get train, validation, test splits\n",
        "trainX, X_validation, testX, trainY, y_validation, testY = prepare_datasets(0.25, 0.2, data, labels)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/data4/cough_i\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1600/1600 [05:23<00:00,  4.95it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/data4/not cough\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1600/1600 [05:22<00:00,  4.96it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 ... 1 0 1]\n",
            "[[1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK3HJIIgv18E"
      },
      "source": [
        "batch_size = 20 #40\n",
        "epochs = 10 #200\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "input_tensor = Input(shape=(224,224,3))\n",
        "\n",
        "#nb_training_samples =  2560  # 1600\n",
        "#nb_validation_samples =  256 # 400 # Set parameter values\n",
        "\n",
        "n_targets = 2\n",
        "\n",
        "#%%\n",
        "# validation generator configuration\n",
        "#validation_data_dir = 'wavelets_cough_notcough/testing/'\n",
        "aug = ImageDataGenerator(\n",
        "\trotation_range=20,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBB7CWkjwfpS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "612f9362-2fe9-4402-ff70-3d9365fdf16c"
      },
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
        "print('Model loaded.')\n",
        "base_model.summary()\n",
        "\n",
        "#%%\n",
        "\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(n_targets, activation='softmax'))\n",
        "top_model.summary()\n",
        "\n",
        "\n",
        "#%%\n",
        "\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
        "model.summary()\n",
        "\n",
        "\n",
        "#%%\n",
        "\n",
        "num_layers_to_freeze = 15\n",
        "\n",
        "\n",
        "#%%\n",
        "\n",
        "for layer in model.layers[:num_layers_to_freeze]:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "model.compile(optimizer=optimizers.SGD(lr=1e-4, momentum=0.9), \n",
        "                      loss='categorical_crossentropy', \n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "model_filename = \"/content/drive/MyDrive/model_cough/vgg16_model_{}_frozen_layers.json\".format(num_layers_to_freeze)\n",
        "\n",
        "with open(model_filename, \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "    \n",
        "    \n",
        "#%%\n",
        "\n",
        "filepath = \"/content/drive/MyDrive/model_cough/esc50_vgg16_stft_weights_train_last_2_base_layers_best.hdf5\"\n",
        "\n",
        "best_model_checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [best_model_checkpoint]\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    aug.flow(trainX, trainY, batch_size=batch_size),\n",
        "    steps_per_epoch=len(trainX)//batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(X_validation, y_validation),\n",
        "    validation_steps=len(X_validation)//batch_size,\n",
        "    callbacks=callbacks_list)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "Model loaded.\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               6422784   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 6,423,298\n",
            "Trainable params: 6,423,298\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 2)                 6423298   \n",
            "=================================================================\n",
            "Total params: 21,137,986\n",
            "Trainable params: 21,137,986\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "96/96 [==============================] - 61s 254ms/step - loss: 2.2775 - accuracy: 0.6601 - val_loss: 0.4590 - val_accuracy: 0.8083\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 2/10\n",
            "96/96 [==============================] - 24s 252ms/step - loss: 0.3839 - accuracy: 0.8350 - val_loss: 0.3134 - val_accuracy: 0.8833\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 3/10\n",
            "96/96 [==============================] - 24s 254ms/step - loss: 0.3524 - accuracy: 0.8424 - val_loss: 0.3987 - val_accuracy: 0.8833\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 4/10\n",
            "96/96 [==============================] - 25s 255ms/step - loss: 0.2024 - accuracy: 0.9148 - val_loss: 0.1628 - val_accuracy: 0.9333\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 5/10\n",
            "96/96 [==============================] - 25s 258ms/step - loss: 0.1819 - accuracy: 0.9319 - val_loss: 0.1429 - val_accuracy: 0.9354\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 6/10\n",
            "96/96 [==============================] - 25s 256ms/step - loss: 0.1348 - accuracy: 0.9471 - val_loss: 0.0729 - val_accuracy: 0.9708\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 7/10\n",
            "96/96 [==============================] - 25s 256ms/step - loss: 0.1373 - accuracy: 0.9439 - val_loss: 0.0826 - val_accuracy: 0.9729\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 8/10\n",
            "96/96 [==============================] - 25s 258ms/step - loss: 0.1142 - accuracy: 0.9587 - val_loss: 0.0652 - val_accuracy: 0.9750\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 9/10\n",
            "96/96 [==============================] - 25s 257ms/step - loss: 0.0787 - accuracy: 0.9712 - val_loss: 0.0200 - val_accuracy: 0.9917\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 10/10\n",
            "96/96 [==============================] - 25s 256ms/step - loss: 0.0636 - accuracy: 0.9722 - val_loss: 0.0257 - val_accuracy: 0.9937\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4016133bd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16jXPb9HpLRi",
        "outputId": "c0e64727-8bb5-48f6-950d-c1cdae49d5f7"
      },
      "source": [
        "# evaluate model on test set\n",
        "test_loss, test_acc = model.evaluate(testX, testY, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)\n",
        "model.save_weights(filepath)\n",
        "model.save(\"/content/drive/MyDrive/model_cough/cough_detector.model\", save_format=\"h5\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25/25 - 9s - loss: 0.0225 - accuracy: 0.9950\n",
            "\n",
            "Test accuracy: 0.9950000047683716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H__Dp3grLiU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}